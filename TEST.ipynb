{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import Modules\n",
    "import Sequential\n",
    "import Optimizer\n",
    "\n",
    "def generate_disc_set(nb_sample):\n",
    "    \n",
    "    data = torch.empty(nb_sample, 2).uniform_(0, 1)\n",
    "    labels = data.sub(0.5).pow(2).sum(1).sub(1/(2*math.pi)).sign().add(1).div(2).long()\n",
    "    \n",
    "    data_out = data[torch.where(labels==1)]\n",
    "    data_in = data[torch.where(labels==0)]\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(data_out[:,0],data_out[:,1])\n",
    "    plt.scatter(data_in[:,0], data_in[:,1])\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "data, target = generate_disc_set(1000)\n",
    "input1 = data[0:4]\n",
    "target1 = target[0:4]\n",
    "m1 = Modules.Linear(2,25)\n",
    "m2 = Modules.Linear(25,25)\n",
    "m3 = Modules.Linear(25,25)\n",
    "m4 = Modules.Linear(25,2)\n",
    "relu = Modules.ReLu()\n",
    "MSE = Modules.MSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Train :\n",
    "\n",
    "nb_epochs = 25\n",
    "losses = []\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    \n",
    "    output = relu(m4(relu(m2(relu(m1(data))))))\n",
    "    loss = MSE(output,target)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-5.0944e-01,  1.3551e-01, -1.9024e-04, -1.3056e-01, -5.5786e-03,\n",
      "         -2.5049e-01,  2.5344e-01, -6.1906e-02,  3.2406e-02, -1.7856e-01,\n",
      "         -5.4061e-02,  3.6797e-01,  2.6338e-01,  4.9275e-02, -1.5464e-03,\n",
      "          7.1241e-02, -1.1831e-01,  3.7610e-01,  3.1718e-02,  8.6412e-02,\n",
      "          2.0217e-02,  1.9672e-02, -4.3603e-01, -1.3065e-01,  8.5013e-02],\n",
      "        [ 2.1008e-01, -1.2571e-01,  4.5521e-01,  4.5020e-02, -4.5911e-02,\n",
      "         -1.1428e-01, -7.5656e-02, -9.8535e-02,  1.1779e-01, -1.0714e-01,\n",
      "          1.5161e-01, -2.6421e-01, -4.1218e-01, -2.8623e-01, -5.7988e-03,\n",
      "         -3.9656e-02, -2.4367e-01,  3.3731e-01, -3.9422e-02,  2.5710e-01,\n",
      "         -7.7596e-02,  6.9042e-02, -2.9073e-02, -1.4491e-01, -2.6884e-03],\n",
      "        [-6.8019e-03,  1.5937e-01, -2.7828e-01, -8.2101e-02, -3.2697e-02,\n",
      "         -8.3558e-02, -3.1161e-01, -2.5578e-02,  1.5588e-01, -6.0819e-02,\n",
      "          4.0372e-01,  1.7340e-01, -1.3393e-01, -1.6414e-01,  1.0238e-02,\n",
      "          3.5451e-02, -9.3340e-02,  6.6384e-02,  2.7493e-01,  2.5466e-01,\n",
      "          2.1476e-01,  3.3607e-01, -3.4470e-02, -4.0614e-01, -3.0589e-01],\n",
      "        [ 5.4414e-02, -1.4583e-02, -2.7640e-02,  3.4863e-02,  2.7352e-02,\n",
      "         -2.7726e-01,  4.4390e-02, -1.7957e-01,  4.3300e-02,  1.7574e-01,\n",
      "          2.5421e-01, -6.4564e-02, -1.7291e-01, -7.6555e-02, -2.5128e-01,\n",
      "          1.6409e-01,  9.0883e-02, -2.0219e-02, -5.0826e-02,  2.5090e-01,\n",
      "         -7.4005e-02, -2.2442e-01, -4.8723e-02,  2.6176e-01,  1.2718e-03],\n",
      "        [ 8.9159e-02,  4.8080e-02,  1.9041e-01, -1.3342e-01, -3.0452e-01,\n",
      "          3.9068e-02, -1.3887e-01,  2.0451e-01,  1.6561e-01, -2.8612e-01,\n",
      "          1.6619e-01,  3.4716e-02, -1.1696e-01, -1.9139e-01, -2.4708e-01,\n",
      "         -1.6557e-01,  3.7690e-02,  5.2899e-02, -1.4702e-01, -3.2560e-01,\n",
      "          2.6907e-01,  6.1507e-02, -1.4702e-02, -4.5318e-02, -6.8321e-02],\n",
      "        [-3.0450e-01,  1.6255e-01,  1.8115e-01,  1.6033e-01, -2.6636e-01,\n",
      "          2.1978e-01, -1.4192e-02,  1.4761e-01, -2.6863e-02,  1.2760e-01,\n",
      "         -2.9873e-01, -1.4793e-01,  3.3634e-01, -1.7378e-01,  8.2224e-02,\n",
      "         -4.0363e-02,  3.4536e-01, -2.8731e-01,  8.0376e-02, -2.1051e-01,\n",
      "          1.0081e-01,  1.0321e-01,  1.7091e-01,  4.4049e-01, -3.9711e-02],\n",
      "        [ 4.4038e-02, -2.9734e-01,  2.7830e-01, -6.4293e-02, -3.8844e-01,\n",
      "         -7.3778e-02, -1.0299e-01, -1.4303e-01, -9.1434e-02,  7.5037e-02,\n",
      "          2.2325e-01, -1.4233e-01, -1.6546e-01, -2.1252e-01, -3.3267e-02,\n",
      "          2.3221e-01,  1.1117e-01,  1.1681e-01, -1.1873e-02,  2.5546e-01,\n",
      "         -2.3231e-02, -2.4022e-02, -6.3234e-02,  4.7472e-02,  2.4720e-01],\n",
      "        [-4.0457e-01, -3.6260e-01,  1.5941e-01, -2.1982e-01,  3.2496e-01,\n",
      "         -1.1157e-01,  1.2063e-01,  2.8985e-01,  1.6229e-01,  4.3752e-02,\n",
      "         -2.4584e-01, -1.8594e-01, -1.8612e-01, -2.7645e-01,  2.2646e-01,\n",
      "          2.2647e-01, -3.7354e-01, -1.5727e-01, -9.6785e-03, -1.7466e-01,\n",
      "         -1.0735e-01, -3.2473e-02,  6.1660e-03, -5.5890e-02,  4.7933e-02],\n",
      "        [-2.5420e-01,  1.2129e-01,  3.2132e-01,  8.4783e-02, -1.2128e-01,\n",
      "          6.2385e-02,  2.1775e-01,  1.6824e-01, -1.4984e-01,  8.7054e-02,\n",
      "         -1.0360e-02,  1.7417e-01, -3.0609e-02,  2.1439e-01, -3.0319e-02,\n",
      "         -2.6187e-01, -1.9132e-01, -2.9323e-01,  2.3474e-01, -2.0465e-01,\n",
      "         -3.2553e-01, -6.5917e-02, -1.1590e-01, -2.2472e-01, -1.7947e-01],\n",
      "        [-4.3648e-01, -1.3346e-01, -7.9649e-02, -2.1410e-01,  4.1837e-02,\n",
      "          3.4815e-01, -3.7778e-01,  2.8290e-01,  1.2399e-01, -7.7955e-02,\n",
      "         -5.6274e-02,  2.6935e-01,  1.6552e-01,  2.3227e-01, -2.1286e-02,\n",
      "          5.6371e-02,  2.6550e-01,  2.6036e-02,  3.1372e-01, -1.2583e-01,\n",
      "         -1.1434e-02, -1.9798e-01,  7.1873e-01,  8.6665e-02, -3.6016e-01],\n",
      "        [ 1.8426e-01,  5.9439e-02,  2.0240e-02,  2.4379e-01, -4.6198e-01,\n",
      "          6.9861e-02, -8.7221e-02, -1.4552e-01,  1.3771e-01, -1.5452e-01,\n",
      "         -1.1273e-01, -3.8760e-01, -1.1847e-01, -3.0403e-01,  3.1760e-02,\n",
      "          2.9923e-01,  1.4074e-01,  2.5509e-01,  1.2961e-01, -1.1603e-01,\n",
      "          3.8952e-01,  2.3586e-01, -2.2176e-01, -2.4338e-01,  1.5034e-02],\n",
      "        [ 3.7783e-03, -2.4255e-01,  4.2943e-02,  6.8565e-02,  1.5846e-01,\n",
      "         -1.1225e-02, -2.1610e-01, -1.4958e-01,  5.8647e-02,  9.1213e-02,\n",
      "         -9.0791e-02,  7.9731e-02, -2.0692e-01,  9.3546e-04,  1.2962e-01,\n",
      "         -1.5710e-01,  8.2638e-02, -2.7098e-01,  6.7746e-03,  8.1022e-02,\n",
      "          1.2353e-01, -3.1190e-02, -1.7126e-01, -1.5162e-01, -1.8408e-01],\n",
      "        [ 1.4904e-01,  5.9594e-02,  8.7522e-03,  2.7052e-01,  5.7088e-02,\n",
      "         -2.3354e-01, -4.8038e-02, -2.2668e-02,  9.3545e-02,  2.9960e-02,\n",
      "         -1.8917e-01,  1.2172e-01,  8.9793e-02, -5.9281e-03,  3.6997e-01,\n",
      "          2.5231e-01, -1.1173e-01, -2.8797e-01,  2.3745e-01,  2.5040e-01,\n",
      "          6.7804e-02, -2.6559e-01,  4.4660e-02,  2.2734e-01, -2.3333e-02],\n",
      "        [ 2.1841e-01,  1.9091e-01, -7.7395e-02,  5.4369e-02, -6.6315e-01,\n",
      "          3.3821e-02,  3.7818e-01, -2.0420e-01, -9.7789e-02,  8.7609e-02,\n",
      "          3.3273e-01, -1.1093e-02,  3.6496e-01,  1.2674e-01, -7.5856e-02,\n",
      "         -2.3352e-01,  4.3894e-01,  3.6577e-01,  7.1872e-02, -2.3721e-01,\n",
      "          9.9605e-02,  2.8222e-02,  2.0455e-01, -3.0533e-01,  1.9708e-03],\n",
      "        [-1.5526e-01,  1.5818e-02,  3.1979e-01,  1.6044e-02, -1.8598e-01,\n",
      "          4.6058e-03,  6.9220e-02, -2.3802e-01,  1.6244e-01, -5.4007e-02,\n",
      "         -6.8155e-02,  2.3128e-01, -1.2443e-03,  6.5909e-02, -3.9708e-02,\n",
      "         -1.0056e-01,  3.3743e-01,  1.5962e-04, -2.1081e-01, -2.8532e-02,\n",
      "         -2.4782e-02,  1.6087e-01,  5.4939e-02,  9.3900e-02,  4.6043e-01],\n",
      "        [-7.0220e-02, -2.4594e-01, -1.2550e-01,  1.8079e-01,  4.6755e-02,\n",
      "         -1.6338e-02, -2.9571e-01,  2.4570e-01, -1.1200e-01, -6.1857e-02,\n",
      "          2.5697e-02,  5.8329e-02, -9.9771e-02,  9.3760e-02, -2.5801e-01,\n",
      "          1.3710e-02,  2.5311e-01,  2.4535e-01, -3.7949e-01,  1.0207e-01,\n",
      "          2.3439e-01,  1.2785e-01,  4.7029e-02,  1.7687e-01,  1.7995e-01],\n",
      "        [ 3.6292e-01,  2.0434e-01,  1.6925e-01,  9.7059e-02, -1.1736e-02,\n",
      "          1.4709e-01,  2.3597e-02,  4.3601e-01, -3.3450e-01, -5.6144e-02,\n",
      "         -2.0507e-01,  6.7287e-02,  1.6641e-01,  8.4493e-02, -7.7833e-02,\n",
      "          3.0583e-01,  8.9986e-02,  2.3656e-01, -1.4938e-01, -1.0383e-02,\n",
      "          1.9259e-01,  1.6983e-01,  1.0527e-01, -2.6093e-01, -2.7981e-03],\n",
      "        [ 9.3470e-02,  1.7433e-01,  2.1990e-01,  1.4739e-01, -3.3620e-01,\n",
      "          2.3394e-01,  1.6260e-01, -2.5422e-01, -2.5089e-02, -1.6894e-01,\n",
      "          1.0871e-01, -3.9843e-02,  1.9828e-02, -3.2714e-01, -3.5113e-01,\n",
      "          7.4888e-02, -5.3286e-02,  6.8385e-02,  2.0131e-01,  1.4760e-02,\n",
      "         -1.1988e-02,  1.4356e-01, -1.5007e-01, -1.7289e-01,  3.6258e-02],\n",
      "        [ 5.5587e-02, -4.0088e-01,  2.3503e-01, -1.2483e-01,  2.4056e-01,\n",
      "          1.2130e-01,  4.3147e-01,  2.3482e-01,  1.3923e-01, -3.6648e-01,\n",
      "          1.6385e-01,  1.0848e-01,  1.6416e-01,  6.3383e-02,  8.4030e-02,\n",
      "         -3.9063e-02, -1.3386e-01,  7.6182e-02,  7.7577e-02, -5.5128e-02,\n",
      "         -4.4778e-01,  2.6614e-01,  3.7141e-01, -2.3176e-01, -4.4512e-01],\n",
      "        [ 1.6789e-01, -3.0960e-01, -3.0547e-02,  7.3056e-02, -2.5983e-01,\n",
      "         -1.3011e-01, -2.7188e-01, -4.6895e-02,  1.0982e-01,  3.4380e-02,\n",
      "          9.4794e-02, -4.3754e-04, -9.7284e-02,  8.8506e-02, -2.2325e-02,\n",
      "          8.4205e-02,  1.0319e-02,  2.1522e-01,  8.4452e-03, -1.1058e-02,\n",
      "          3.4899e-01,  2.8498e-02,  6.7986e-02,  3.9266e-02, -1.0030e-01],\n",
      "        [ 1.8340e-01, -5.3839e-01,  2.0235e-01,  1.0647e-01, -1.5161e-01,\n",
      "          1.5393e-01, -5.5906e-02, -1.3262e-01, -1.6747e-01,  3.8271e-01,\n",
      "         -5.6824e-02,  7.9060e-02, -3.2857e-01,  1.1243e-01, -1.3799e-01,\n",
      "         -2.6031e-01,  8.9224e-04,  5.5743e-02,  2.8909e-01,  1.8739e-01,\n",
      "         -3.8610e-01, -2.1164e-01, -1.9011e-01,  1.2340e-01, -1.0460e-01],\n",
      "        [-1.3366e-01,  4.0988e-02, -9.0318e-02, -2.2169e-01, -5.2899e-03,\n",
      "         -3.5459e-01,  1.3801e-01, -2.5752e-01,  2.5331e-01, -1.9129e-01,\n",
      "         -1.5330e-01, -3.8874e-01,  9.5747e-02, -1.7725e-01,  2.2561e-01,\n",
      "         -3.5013e-01, -1.3857e-01, -1.7804e-01,  3.2440e-02,  2.3229e-02,\n",
      "          1.8084e-01, -1.8615e-02, -1.9205e-01,  2.3326e-01,  3.1619e-01],\n",
      "        [-3.3160e-01, -4.9305e-02,  3.2118e-01, -3.4496e-01,  1.1957e-01,\n",
      "          1.7732e-01,  5.0160e-01,  4.1110e-02,  1.7438e-01, -7.0355e-02,\n",
      "         -6.1844e-01, -2.3689e-01,  3.4311e-01,  2.5627e-01,  1.7060e-01,\n",
      "          1.5481e-01,  2.1548e-01, -1.2269e-01,  1.3866e-01, -1.3263e-01,\n",
      "         -2.0010e-01, -2.7207e-02, -3.6431e-01,  1.8714e-01,  2.1146e-01],\n",
      "        [-3.9236e-02, -2.0764e-03, -1.3910e-01, -3.1955e-01,  1.1111e-02,\n",
      "         -1.1366e-01,  1.0142e-01, -1.3558e-01, -8.1713e-02, -4.8368e-01,\n",
      "         -1.4061e-01,  1.3040e-01,  2.8956e-01,  6.1862e-01,  2.1656e-01,\n",
      "         -4.1829e-02, -1.1192e-01,  1.5971e-01,  2.0293e-01,  1.1172e-01,\n",
      "         -2.4998e-01,  1.2009e-01,  3.4423e-01,  3.2034e-02,  1.4809e-01],\n",
      "        [-5.9972e-02,  4.8899e-01,  1.8936e-01,  4.3037e-01,  1.9786e-01,\n",
      "          6.8391e-02, -7.5159e-02,  2.1655e-01, -2.2390e-01, -1.5664e-01,\n",
      "         -4.0287e-01,  9.6939e-02,  6.0122e-02, -7.7280e-02,  2.4224e-02,\n",
      "         -2.1097e-01,  1.9844e-01,  5.2087e-02, -2.6812e-03, -8.3309e-02,\n",
      "          4.8225e-02, -2.5639e-02, -1.6439e-01,  2.1057e-01,  2.9136e-02]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.]]), tensor([-1.5856e-01, -2.0131e-02,  3.9018e-01,  1.3327e-01,  1.5589e-02,\n",
      "         9.3203e-02,  3.7704e-01, -7.6499e-02, -1.8101e-02,  6.6241e-02,\n",
      "         5.1455e-02, -8.2568e-02, -1.5941e-01,  1.4361e-02,  2.2484e-01,\n",
      "        -1.3511e-01, -2.0308e-01,  1.4141e-01,  7.2549e-02,  1.6334e-01,\n",
      "         1.0214e-04,  4.4345e-02, -5.3377e-01,  1.8336e-02, -2.1762e-01]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0.])]\n"
     ]
    }
   ],
   "source": [
    "print(m2.param())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Modules.ReLu at 0x1fe986b2588>,\n",
       " <Modules.Linear at 0x1fe986a6308>,\n",
       " <Modules.ReLu at 0x1fe986b2588>,\n",
       " <Modules.Linear at 0x1fe93ecc088>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mseq = Sequential.Sequential(m1,relu,m2,relu)\n",
    "mseq.members[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Modules.Linear object at 0x000001629235DF08>, <Modules.ReLu object at 0x0000016296B08E48>, <Modules.Linear object at 0x0000016296549908>, <Modules.ReLu object at 0x0000016296B08E48>]\n",
      "0 Module : <Modules.ReLu object at 0x0000016296B08E48>\n",
      "1 Module : <Modules.Linear object at 0x0000016296549908>\n",
      "2 Module : <Modules.ReLu object at 0x0000016296B08E48>\n",
      "3 Module : <Modules.Linear object at 0x000001629235DF08>\n",
      "\n",
      "\n",
      "0 Module : <Modules.Linear object at 0x000001629235DF08>\n",
      "1 Module : <Modules.ReLu object at 0x0000016296B08E48>\n",
      "2 Module : <Modules.Linear object at 0x0000016296549908>\n",
      "3 Module : <Modules.ReLu object at 0x0000016296B08E48>\n",
      "0 3\n",
      "1 2\n",
      "2 1\n",
      "3 0\n"
     ]
    }
   ],
   "source": [
    "print(mseq.members)\n",
    "z = mseq.members[::-1]\n",
    "for index, module in enumerate(z):\n",
    "    print(index, \"Module :\",module)\n",
    "print(\"\\n\")\n",
    "for index, module in enumerate(mseq.members):\n",
    "    print(index, \"Module :\",mseq.members[index])\n",
    "range1=range(4)\n",
    "for index, number in enumerate(range1):\n",
    "    print(index,range1[-index-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.3909],\n",
      "        [0.0000, 0.4666],\n",
      "        [0.0000, 0.4236],\n",
      "        ...,\n",
      "        [0.0000, 0.4817],\n",
      "        [0.0000, 0.3958],\n",
      "        [0.0000, 0.4676]])\n",
      "tensor([0, 0, 1, 0])\n",
      "tensor([[-2.0000,  0.7818],\n",
      "        [-2.0000,  0.9333],\n",
      "        [ 0.0000, -1.1528],\n",
      "        ...,\n",
      "        [-2.0000,  0.9633],\n",
      "        [-2.0000,  0.7916],\n",
      "        [ 0.0000, -1.0648]])\n",
      "[<Modules.Linear object at 0x0000020DA8A42848>, <Modules.ReLu object at 0x0000020DA8A5FF08>, <Modules.Linear object at 0x0000020DA37C6908>, <Modules.ReLu object at 0x0000020DA8A5FF08>, <Modules.Linear object at 0x0000020DA7E29488>, <Modules.ReLu object at 0x0000020DA8A5FF08>, <Modules.Linear object at 0x0000020DA423CF08>, <Modules.ReLu object at 0x0000020DA8A5FF08>]\n",
      "first dl: tensor([[-2.0000,  0.7818],\n",
      "        [-2.0000,  0.9333],\n",
      "        [ 0.0000, -1.1528],\n",
      "        ...,\n",
      "        [-2.0000,  0.9633],\n",
      "        [-2.0000,  0.7916],\n",
      "        [ 0.0000, -1.0648]])\n",
      "0 <Modules.ReLu object at 0x0000020DA8A5FF08> tensor([[0.0000, 0.3909],\n",
      "        [0.0000, 0.4666],\n",
      "        [0.0000, 0.4236],\n",
      "        ...,\n",
      "        [0.0000, 0.4817],\n",
      "        [0.0000, 0.3958],\n",
      "        [0.0000, 0.4676]])\n",
      "\n",
      " DL : torch.Size([1000, 2]) tensor([[-2.0000,  0.7818],\n",
      "        [-2.0000,  0.9333],\n",
      "        [ 0.0000, -1.1528],\n",
      "        ...,\n",
      "        [-2.0000,  0.9633],\n",
      "        [-2.0000,  0.7916],\n",
      "        [ 0.0000, -1.0648]])\n",
      "1 <Modules.Linear object at 0x0000020DA423CF08> tensor([[-0.5160,  0.3909],\n",
      "        [-0.5118,  0.4666],\n",
      "        [-0.5318,  0.4236],\n",
      "        ...,\n",
      "        [-0.5151,  0.4817],\n",
      "        [-0.5277,  0.3958],\n",
      "        [-0.5289,  0.4676]])\n",
      "\n",
      " DL : torch.Size([1000, 2]) tensor([[-0.0000,  0.7818],\n",
      "        [-0.0000,  0.9333],\n",
      "        [ 0.0000, -1.1528],\n",
      "        ...,\n",
      "        [-0.0000,  0.9633],\n",
      "        [-0.0000,  0.7916],\n",
      "        [ 0.0000, -1.0648]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1, 2] doesn't match the broadcast shape [1000, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-496d2f1ac03e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#print(len(model.members))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdl_dx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;31m#for e in range(nb_epochs):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#    output = model(input1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\richi\\Documents\\EPFL\\Master\\MA4\\Deep Learning\\Mini_project\\project2\\dl_project2\\Sequential.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, dl)\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n DL :\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mdl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlossmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m#reversed loss memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\richi\\Documents\\EPFL\\Master\\MA4\\Deep Learning\\Mini_project\\project2\\dl_project2\\Modules.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, x, dl_ds)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m#print(self.db.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdl_ds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdl_ds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdl_dx_prev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: output with shape [1, 2] doesn't match the broadcast shape [1000, 2]"
     ]
    }
   ],
   "source": [
    "nb_epochs = 25\n",
    "mini_batch_size = 200\n",
    "\n",
    "model = Sequential.Sequential(m1,relu,m2,relu,m3,relu,m4,relu)\n",
    "output = model(data)\n",
    "loss = MSE(output,target)\n",
    "model.zero_grad()\n",
    "dl_dx = MSE.backward(output,target)\n",
    "print(dl_dx)\n",
    "#for index, memory in enumerate(model.memory):\n",
    "#    print(model.members[index])\n",
    "#    print(index,\": memory size \",memory.size(), \"\\n\", memory,\"\\n\")\n",
    "#print(len(model.members))\n",
    "\n",
    "errors = model.backward(dl_dx)\n",
    "#for e in range(nb_epochs):\n",
    "#    output = model(input1)\n",
    "#    loss = MSE(output,target1)\n",
    "#    model.zero_grad()\n",
    "#    dl_dx = MSE.backward(output,target1)\n",
    "#    model.backward(dl_dx)\n",
    "       \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 4])\n",
      "torch.Size([25, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.empty(4,25)\n",
    "b = torch.empty(4,2)\n",
    "print(a.t().size())\n",
    "print(a.t().mm(b).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1,2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
